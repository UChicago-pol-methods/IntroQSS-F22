---
title: "PLSC30500, Fall 2022"
subtitle: "Week 7. Estimation (2)"
# author: "Andy Eggers & Molly Offer-Westort"
output: 
  xaringan::moon_reader:
    self_contained: true
    css: [default, uchicago_pol_meth.css]
    nature:
      highlightLines: true
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(fig.height=5, fig.width=8.5, fig.align="center", warning = F, message = F)
```



class: inverse, middle, center

# Conditional expectations


---

# Conditional expectation: definition

$$E [Y | X = x] = \sum_y y f_{Y|X}(y | x)$$ 

i.e. the expectation of $Y$ at some $x$. 

---

# Conditional expectation: illustration 

Suppose $f_X(x)$ is uniform, and $f_{Y|X}(y|x)$ normal, with mean of $3x + 8x^2 - 3x^3$ and variance of $9$.

Then what is $E [Y | X = x] = \sum_y y f_{Y|X}(y | x)$ at $x = 1$?

--

```{r, fig.height = 4.5, echo = F}
n <- 1000
p <- tibble(x = runif(n, min = 0, max = 2.75)) |> 
  mutate(mu = 3*x + 8*x^2 - 3*x^3,
         y = rnorm(n, mean = mu, sd = 3)) |> 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5, size = 2) +
  theme_bw() + 
  geom_line(aes(y = mu), col = "red", lwd = 2)
p
```



---

# Conditional variance

Two formulations: 

$$V[Y | X = x] = E[(Y - E[Y | X =x])^2 | X = x]$$
$$V[Y | X = x] = E[Y^2 | X = x] - E[Y | X =x]^2$$
--

```{r, fig.height = 5, echo = F}
p
```

---

# Conditional variance (2)


Two formulations: 

$$V[Y | X = x] = E[(Y - E[Y | X =x])^2 | X = x]$$

$$V[Y | X = x] = E[Y^2 | X = x] - E[Y | X =x]^2$$

```{r, echo = F}
tibble(x = runif(n, min = 0, max = 2.75)) |> 
  mutate(mu = 3*x + 8*x^2 - 3*x^3,
         y = rnorm(n, mean = mu, sd = 1 + x)) |> 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5, size = 2) +
  theme_bw() + 
  geom_line(aes(y = mu), col = "red", lwd = 2)
```


---

# CEF

Conditional expectation $E[Y | X = x]$ is for a specific $x$.

Conditional expectation function (CEF) $E[Y | X]$ is for all $x$.

--

Suppose again $f_X(x)$ is uniform, and $f_{Y|X}(y|x)$ normal, with mean of $3x + 8x^2 - 3x^3$ and variance of $9$.

Then what is $E [Y | X ]$?

```{r, echo = F, fig.height = 4.5}
p
```


---

# Law of iterated expectations

**Theorem 2.2.17**. *Law of iterated expectations*

For random variables $X$ and $Y$,

$$E[Y] = E[E[Y | X]]$$
--

In words: to get the average of $Y$, you can take the average of $Y$ within levels of $X$ and then average those according to the distribution of $X$.

---

# LIE: An intuitive example

A population is 80% female and 20% male.

The average age among females is 25. The average age among males is 20.

What is the average age in the population?

--

$$E[E[Y | X]] = .8 \times 25 + .2 \times 20 = 24$$

---

# LIE: another example

```{r, echo = F}
p
```


---

# LIE: another example (2)

```{r, echo = F}
n <- 5000
tibble(x = rnorm(n, mean = 3, sd = 1.5)) |> 
  mutate(mu = 3*x + 8*x^2 - 3*x^3,
         y = rnorm(n, mean = mu, sd = 3)) |> 
  filter(x > 0 & x < 2.75) |> 
  ggplot(aes(x = x, y = y)) + 
  geom_point(alpha = .5, size = 2) +
  theme_bw() + 
  geom_line(aes(y = mu), col = "red", lwd = 2)
```

---

## How LIE is used (preview)

Suppose we want to estimate

$$\text{ATE} = E[Y_i(1) - Y_i(0)] = E[Y_i(1)] - E[Y_i(0)]$$.

--

How did we estimate $E[Y_i(1)]$ and $E[Y_i(0)]$ via randomization?

--

Suppose randomization impossible. By LIE,
$$\begin{aligned} 
E[Y_i(1)] &= E[E[Y_i(1) | X_i]] \\\
 &= \sum_x E[Y_i(1) | X_i = x] \text{Pr}[X_i = x]
\end{aligned}$$
(And same for $Y_i(0)$.)

--

Now suppose $E[Y_i(1) | X_i = x] = E[Y_i | D_i = 1, X_i = x] \, \forall x$ (**strong ignorability**), and same for $Y_i(0)$.

--

Then we can plug in above, and the ATE is **identified**.

???

Intuitively, is there a covariate such that, conditional on that covariate, the observed outcomes for the treated units are the counterfactual values for the control units with those same values of the covariate?

If so, by LIE (and SUTVA), you have identified the treatment effect.

---

# Law of total variance

---

# Best predictors, BLP

